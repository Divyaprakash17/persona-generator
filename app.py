import os
import sys
import streamlit as st
from scraper import RedditScraper
from persona_generator import PersonaGenerator
import json
from datetime import datetime

# Add the current directory to Python path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# Set page config first
st.set_page_config(
    page_title="Reddit User Persona Generator",
    page_icon="ğŸ§ ",
    layout="centered"
)

def get_api_keys():
    """Get API keys from Streamlit secrets"""
    try:
        # Try to get secrets from the root level first
        GOOGLE_API_KEY = st.secrets.get('GOOGLE_API_KEY')
        REDDIT_CLIENT_ID = st.secrets.get('REDDIT_CLIENT_ID')
        REDDIT_CLIENT_SECRET = st.secrets.get('REDDIT_CLIENT_SECRET')
        REDDIT_USER_AGENT = st.secrets.get('REDDIT_USER_AGENT')
        
        # If not found, try from the 'api' section
        if not all([GOOGLE_API_KEY, REDDIT_CLIENT_ID, REDDIT_CLIENT_SECRET, REDDIT_USER_AGENT]):
            api_secrets = st.secrets.get('api', {})
            GOOGLE_API_KEY = api_secrets.get('GOOGLE_API_KEY')
            REDDIT_CLIENT_ID = api_secrets.get('REDDIT_CLIENT_ID')
            REDDIT_CLIENT_SECRET = api_secrets.get('REDDIT_CLIENT_SECRET')
            REDDIT_USER_AGENT = api_secrets.get('REDDIT_USER_AGENT')
        
        if not all([GOOGLE_API_KEY, REDDIT_CLIENT_ID, REDDIT_CLIENT_SECRET, REDDIT_USER_AGENT]):
            raise ValueError("Missing required API keys")
            
        return {
            'GOOGLE_API_KEY': GOOGLE_API_KEY,
            'REDDIT_CLIENT_ID': REDDIT_CLIENT_ID,
            'REDDIT_CLIENT_SECRET': REDDIT_CLIENT_SECRET,
            'REDDIT_USER_AGENT': REDDIT_USER_AGENT
        }
    except Exception as e:
        raise ValueError(f"Error loading API keys: {str(e)}")

def save_persona(persona_text: str, username: str) -> str:
    """
    Save the generated persona to a well-formatted text file with all citations.
    
    Args:
        persona_text: The generated persona text with citations
        username: The Reddit username
        
    Returns:
        Path to the saved file
    """
    try:
        # Create output directory if it doesn't exist
        os.makedirs("output", exist_ok=True)
        
        # Create a safe filename
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        safe_username = "".join(c for c in username if c.isalnum() or c in ('_', '-')).rstrip()
        filename = f"output/persona_{safe_username}_{timestamp}.txt"
        
        # Create a header with metadata
        header = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘            REDDIT PERSONA ANALYSIS       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â€¢ Analyzed User: u/{username}
â€¢ Generated: {datetime.now().strftime("%Y-%m-%d at %H:%M")}
â€¢ Source: Reddit Profile Analysis

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘               PERSONA                    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

"""
        
        # Format the persona text with consistent indentation
        formatted_lines = []
        in_quote = False
        
        for line in persona_text.split('\n'):
            line = line.strip()
            if not line:
                formatted_lines.append('')
                continue
                
            # Handle section headers (lines starting with emoji)
            if any(line.startswith(emoji) for emoji in ['ğŸ§‘', 'ğŸ“', 'ğŸ§ ', 'ğŸ’¡', 'ğŸ”„', 'ğŸ˜¤', 'ğŸ¯', 'ğŸ“']):
                formatted_lines.append('\n' + line.upper())
                formatted_lines.append('=' * len(line))
            # Handle quotes (indent them)
            elif line.startswith('"') and line.endswith('"'):
                formatted_lines.append(f"    {line}")
            # Handle bullet points
            elif line.startswith('-'):
                formatted_lines.append(line)
            # Regular text (add as is)
            else:
                formatted_lines.append(line)
        
        # Add footer with source information
        footer = """

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘               SOURCES                    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â€¢ All quotes and data sourced directly from Reddit user activity
â€¢ Analysis performed using AI (Gemini 1.5 Flash)
â€¢ Generated by Reddit Persona Generator

"""
        
        # Write everything to the file
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(header)
            f.write('\n'.join(formatted_lines))
            f.write(footer)
        
        return filename
        
    except Exception as e:
        print(f"Error saving persona: {str(e)}")
        return ""

def main():
    # Initialize session state
    if 'persona' not in st.session_state:
        st.session_state.persona = None
    
    # App title and description
    st.title("ğŸ§  Reddit User Persona Generator")
    st.markdown("Generate detailed user personas from Reddit activity using Google's Gemini AI.")
    
    # Input form
    with st.form("reddit_form"):
        profile_url = st.text_input(
            "Enter Reddit Profile URL",
            placeholder="https://www.reddit.com/user/username/"
        )
        
        submitted = st.form_submit_button("Generate Persona")
        
        if submitted and profile_url:
            try:
                # Clean and extract username
                import re
                username = profile_url.strip()
                
                # If it looks like a URL, try to extract username
                if 'reddit.com' in username or username.startswith(('http://', 'https://', '/user/', '/u/')):
                    match = re.search(r'(?:/user/|/u/|\?id=)([\w-]+)', username)
                    if match:
                        username = match.group(1)
                # Otherwise, treat as direct username (remove any leading @ or u/ if present)
                else:
                    username = re.sub(r'^[uU]/|^@', '', username)
                
                # Validate username
                if not username or not re.match(r'^[\w-]{3,20}$', username):
                    st.error("Please enter a valid Reddit username (3-20 characters, letters, numbers, _ or -)")
                    return
                
                # Block common invalid usernames
                if username.lower() in ['user', 'u', 'comments', 'posts', 'about', 'submit', 'premium', 'settings']:
                    st.error("Please enter a valid Reddit username, not a Reddit section")
                    return
                
                st.info(f"Fetching data for user: u/{username}")
                
                with st.spinner("Fetching user data..."):
                    try:
                        # Get API keys
                        api_keys = get_api_keys()
                        
                        # Initialize scraper with credentials from secrets
                        scraper = RedditScraper(
                            client_id=api_keys['REDDIT_CLIENT_ID'],
                            client_secret=api_keys['REDDIT_CLIENT_SECRET'],
                            user_agent=api_keys['REDDIT_USER_AGENT']
                        )
                        # Fetch user data with more comments and posts
                        user_data = scraper.get_user_data(
                            username=username,
                            comment_limit=100,  # Increased from default 50
                            post_limit=50       # Kept at 50 as posts are typically longer
                        )
                        
                        # If we got data, ensure metadata exists
                        if user_data:
                            if 'metadata' not in user_data:
                                user_data['metadata'] = {}
                                user_data['metadata'].update({
                                    'generated_at': datetime.now().isoformat(),
                                    'model_used': 'gemini-1.5-flash'  # This will be updated by the generator
                                })
                        else:
                            raise ValueError("Failed to fetch user data")
                        
                        # Generate persona with error handling
                        try:
                            with st.spinner("Generating persona with AI..."):
                                # Generate persona
                                generator = PersonaGenerator(
                                    google_api_key=api_keys['GOOGLE_API_KEY']
                                )
                                persona_data = generator.generate_persona(user_data)
                                
                                if persona_data:
                                    # Display the generated persona with proper formatting
                                    st.markdown(persona_data['persona_text'])
                                    
                                    # Show metadata
                                    with st.expander("Analysis Metadata"):
                                        st.write(f"Generated using: {persona_data['metadata']['model_used']}")
                                        st.write(f"Generated at: {persona_data['metadata']['generated_at']}")
                                        st.write(f"Comments analyzed: {persona_data['metadata']['comments_analyzed']}")
                                        st.write(f"Posts analyzed: {persona_data['metadata']['posts_analyzed']}")

                                    # Save persona to file
                                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                                    filename = f"persona_{username}_{timestamp}.txt"
                                    filepath = os.path.join("output", filename)
                                    os.makedirs("output", exist_ok=True)
                                    
                                    with open(filepath, 'w', encoding='utf-8') as f:
                                        f.write(persona_data['persona_text'])
                                        f.write("\n\n")
                                        f.write("ANALYSIS METADATA\n")
                                        f.write(f"Generated using: {persona_data['metadata']['model_used']}\n")
                                        f.write(f"Generated at: {persona_data['metadata']['generated_at']}\n")
                                        f.write(f"Comments analyzed: {persona_data['metadata']['comments_analyzed']}\n")
                                        f.write(f"Posts analyzed: {persona_data['metadata']['posts_analyzed']}")

                                    st.success("Persona generated successfully!")
                                
                        except Exception as e:
                            st.error(f"Error generating persona: {str(e)}")
                            return
                        
                    except ValueError as e:
                        st.error(f"Error: {str(e)}")
                        return
                    except Exception as e:
                        st.error(f"Unexpected error: {str(e)}")
                        return

                        # Save persona to file
                        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                        filename = f"persona_{username}_{timestamp}.txt"
                        filepath = os.path.join("output", filename)
                        os.makedirs("output", exist_ok=True)
                        
                        with open(filepath, 'w', encoding='utf-8') as f:
                            f.write(persona['persona_text'])
                            f.write("\n\n")
                            f.write("ANALYSIS METADATA\n")
                            f.write(f"Generated using: {persona['metadata']['model_used']}\n")
                            f.write(f"Generated at: {persona['metadata']['generated_at']}\n")
                            f.write(f"Comments analyzed: {persona['metadata']['comments_analyzed']}\n")
                            f.write(f"Posts analyzed: {persona['metadata']['posts_analyzed']}")

                        st.success("Persona generated successfully!")
                    
                    # Save to session state
                    st.session_state.persona = persona
                    st.session_state.username = username
                    
                    output_file = save_persona(persona['persona_text'], username)
                    if output_file:
                        st.session_state.filename = output_file
                    else:
                        st.error("Failed to save persona to file.")
                    
            except Exception as e:
                st.error(f"An error occurred: {str(e)}")
                st.stop()
    
    # Display results if available
    if st.session_state.persona and 'persona_text' in st.session_state.persona:
        st.markdown("---")
        st.markdown("## ğŸ“‹ Generated Persona")
        
        # Display the persona text with proper formatting
        persona_text = st.session_state.persona['persona_text']
        
        # Split the text into sections based on emoji headers
        sections = {}
        current_section = None
        
        # Define the section headers we're looking for
        section_headers = [
            'ğŸ§‘â€ğŸ’» Occupation', 'ğŸ“ Location', 'ğŸ§  PERSONALITY', 
            'ğŸ’¡ MOTIVATIONS', 'ğŸ”„ BEHAVIORS & HABITS', 
            'ğŸ˜¤ FRUSTRATIONS', 'ğŸ¯ GOALS & NEEDS', 'ğŸ“ EVIDENCE'
        ]
        
        # Process each line
        for line in persona_text.split('\n'):
            line = line.strip()
            if not line:
                continue
                
            # Check if this line is a section header
            is_header = False
            for header in section_headers:
                if line.startswith(header):
                    current_section = header
                    sections[current_section] = []
                    is_header = True
                    break
                    
            if not is_header and current_section:
                # Add line to current section if it's not empty
                if line.strip() and not line.startswith('-'):
                    sections[current_section].append(line)
        
        # Display each section in the correct order
        for header in section_headers:
            if header in sections and sections[header]:
                content = '\n'.join(sections[header])
                if content.strip():
                    with st.expander(header, expanded=True):
                        st.markdown(content)
        
        # Display any remaining content that wasn't in a section
        remaining_content = []
        for line in persona_text.split('\n'):
            line = line.strip()
            if line and not any(line.startswith(header) for header in section_headers):
                if line.startswith('-'):
                    remaining_content.append(f"- {line[1:].strip()}")
                else:
                    remaining_content.append(line)
        
        if remaining_content:
            with st.expander("Additional Information", expanded=False):
                st.markdown('\n'.join(remaining_content))
        
        # Add some spacing
        st.markdown("\n\n")
        
        # Add download button
        if 'filename' in st.session_state:
            with open(st.session_state.filename, 'r', encoding='utf-8') as f:
                st.download_button(
                    label="ğŸ’¾ Download Persona",
                    data=f,
                    file_name=os.path.basename(st.session_state.filename),
                    mime="text/plain"
                )
        
        # Show success message
        st.success("Persona generated successfully!")
        st.balloons()

if __name__ == "__main__":
    main()
